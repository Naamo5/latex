\documentclass[/home/francois/latex/report/main.tex]{subfiles}

\begin{document}

\chapter{Introduction}

A growing number of logistics companies are incorporating robots to automate order fulfillment and warehousing processes. In storehouses with less and less human presence, automated systems run tasks as storing, moving, scanning and wrapping goods. Logistic robots guarantee a great uptime over manual labor while taking over alienating tasks. Warehousing companies garner the benefits of speed, efficiency and increased profits to remain competitive in a market driven by consumers wishing for faster and more reliable deliveries. The past decade has witnessed a very rapid increase in robots installed in 2017 with 69,000 units â€“ a 162 \% increase over 2016 (26,294) according to the \ac{IFR} \cite{industrialRobot2018}. The same organization estimates that 485,300 unit sales will be sold for the period between 2019 and 2021.

The high expectations of this growing e-commerce market has raised challenges for autonomous systems. Traditional robots programmed with hard-coded moves quickly reach limits when it comes to dealing with order disparities in size, shape, weight, volume and mechanical properties \cite{GQHuang2015}. Logistics robots might be able to adapt to a wide diversity of situations with fewer human-in-the-loop interaction. Those challenging tasks have required major research on various fields such as Object Recognition, Motion Control, Perception, Machine Learning, Reinforcement Learning.

When it comes to deliver goods or assemble a final product, moving an item from one place to another is a recurring task. The earliest known industrial robot is a \textit{programmable transfer machine} as known as \textsc{Unimation} patented by George \textsc{Devol} in 1954 \cite{Wallen2008}. Thus, the first robot aimed to perform the so-called \textit{pick-and-place}. This task consists in picking things up from one location, moving them to another location and placing them. A typical application comes with \ac{SMT} component placement systems. Robotic machines are used to place \ac{SMDs} onto a \ac{PCB}. They are used for high speed, high precision placing of broad range of electronic components, like capacitors, resistors, integrated circuits onto the \ac{PCB}.

With the long-term goal of reducing costs and giving systems more flexibility, \textit{pick-and-place} systems tend to be more generic. Industrial robot systems aim not only to \textit{pick-and-place} at high velocity but also to be able to handle unknown objects. To execute such a global task, there are multiple challenges:
\begin{itemize}
	\item \textbf{picking}: the system has to localize the object and find an efficient way to grasp it;
	\item \textbf{moving}: the robot try to move the object as fast as possible without losing it;
	\item \textbf{placing}: the manipulator should place the object ar a desired position with a desired orientation;
	\item \textbf{overall}: the gripper should not damage the item by squeezing, scratching or shaking it.
\end{itemize}

In order to adress those challenges, some ground-breaking research have been carried in the field of item recognition, object pose w.r.t. the gripper computation, item inertial parameters estimation, item measurement. To this end, researchers have focused on gathering information before, during and after the handling time as a source of improvement. Devices to capture data range from visual sensors (RGB cameras, depth cameras, laser line scanners, structured light sensors, \ldots) to kinetic sensors (\ac{IMUs}, \ac{FT} sensors, scales, \ldots) or to more tool-specific sensors (pressure sensors, tactile sensors, \ldots). Efforts torwards object recognition mainly rely on visual information (with \textit{appearance-based} techniques \cite{Carmichael2002, Schmid1997, Viola2001, Murase1993} or \textit{purely geometric} approaches \cite{Hut1987, Sethi2001}). Features used to identify the object are usely related to the shape, the color or the texture of the object. A few projects aim at estimating the inertial parameters of the object as features for recognition \cite{Kubus2008, Kubus2007, Kubus2014, Farsoni2018}. Inertial parameters comprise the mass, the position of the center of mass and the 6 independent inertia tensor coefficients. Those methods utilize the kinematics measurement data and \ac{FT} measurement to estimate the inertial parameters. However, those approaches make use of specific excitation trajectories that barely fit with industry cycle time expectancies. They also do not take into account the mechanical link between the gripper and the item. On balance, the mass only could be estimated without impacting the time-optimized motion of the robotic arm.

This thesis will focus on the estimation of the mass of a manipulator payload in motion by means of a \ac{FT} sensor.

\section{Motivation}

Within the scope of \textit{pick-and-place}, the mass of the item grasped by the tool of the robotic manipulator is a key information for several enhancements. Mass is a meaningful feature for object recognition. It is also a critical data for the dynamic of the system, hard failures detection and estimation of the pose of the item w.r.t. the end-effector.

Concerning item recognition, it appears that purely vision based approaches may fail if the objects to be identified are similar with respect to their visual characteristics. For instance, there is indeed no visual difference between full and empty bottles of milk that might be treated differently by a robotic system for sorting recyclables. Recognition system based on inertial parameters (or combinations of visual information and inertial data) can tackle this bottleneck.
Visual recognition algorithm can be also computationally expensive. The use of multiple cameras and/or RGB-D cameras coupled with generation of point clouds and/or \ac{CNN} require complex hardware or time-consuming scanning. Time is the most expensive resource in industry and unsatisfactory cycle times are the main reason why many bin-picking solutions have not found their way in warehouses or factory production lines.

Inertial parameters of the item grasped is highly valuable to perform highly-dynamic force-guided or force-guarded motions \cite{Garcia2006, KubusKroger2008}. In some instances, the mass of the object carried by the tool is not negligible in relation to the end-effector and the dynamic is strongly affected.
Also, robotic manipulators are operating with unknown objects of different size, shape, material, texture and so on. As a consequence, they are more likely to yield hard failures: two items grasped instead of one, item lost during motion, item hit due to oversize. Inertial parameters estimation can induce the detection of such shortcomming.

Placing the object at a desired position with a desired orientation require the knowledge of the pose of the item w.r.t. to the tool. Once the mass, the center of mass and the inertia tensor are computed, a rough measure of the size and/or shape, orientation and position of the item can be approximated.

\section{Challenges}

One can notice that whilst the topic of the thesis to identify the mass of the manipulator payload, inertial parameters are at the heart of the report.


  identification of the mass by estimating the item inertial parameters. Explain here why it is fondamental to estimate the 10 inertial parameters to access the mass of the item.


\textit{TODO}

{\it
To measure of the inertial parameters of an item while moving can be tough:

\begin{itemize}
	\item The dynamics of the system can be complex and the emergence of inertial side effect can make the measurement complicated.
	\item The diversity of the grasping tools, the different natures of item handled, the different ways to grip the object make the geometry of the system fickle.
	\item The \ac{FT} sensor can deliver a consistent measurement while static. However, the performance can be reduced when the system is moving (due to noise of measurement, response time, . . .).
	\item In the context of an industrial system, the computation time is a crucial point. A rule  thumb is that the running time should not break the motion of the robot.
\end{itemize}
}

% \ac{FT} sensor is mounted on the wrist of the robotic arm. It easily gets a weight measurement of the grasped item when the robot is static. A reliable static measure required the robotic manipulator to be perfectly standing and the F/T sensor to stabilize. This operation takes roughly 0.5s to be executed. It would be better to be able to measure the mass of an item while the robot is in motion. It may allow saving precious time in a grasping cycle and consequently increase productivity.

\section{Formulation of the Problem}

The research question that addresses this thesis is :

How to reliably measure the mass of a manipulator payload in motion by means of a \ac{FT} sensor?

\textit{TODO}

\section{Scope}

\textit{TODO}

{\it

% \begin{itemize}
% 	\item The implementation of trajectories and motion planning is not part of the project. The solution developed should be scalable on similar systems: robot manipulator with an F/T sensor mounted on the last joint. Items, grasping tool, F/T sensor, robotic arm trajectories can be of different types.
% 	\item The project does not include programming motion planning and control of the robotic arm. It does not cover the improvement of the item recognition strategy. Also, it does not comprise the creation of a dataset to evaluate the method.
% \end{itemize}
}


\section{Report Outline}

\textit{TODO}

{\it
The rest of the report is organized as follows: Chapter \ref{chapter:background} reviews the background pertaining to the thesis: dynamic model and \ac{RTLS} approach. Chapter \ref{chapter:method} presents the methods developped in this project: \ac{RMSD} system, signal filtering and \ac{RGTLS} with \ac{NCE}. Chapter \ref{chapter:setup} depicts the experimental setup for testing the different methods. The experimental results are presented analysed in the chapter \ref{chapter:results}. Finally, in the chapter \ref{chapter:conclusions}, conclusions are drawn and future work presentation closes the report.
}

\end{document}
